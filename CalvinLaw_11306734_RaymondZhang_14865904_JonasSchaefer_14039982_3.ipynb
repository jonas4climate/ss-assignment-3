{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T02:23:32.464640500Z",
     "start_time": "2023-12-22T02:23:32.173506Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.optimize import dual_annealing, curve_fit\n",
    "from scipy.integrate import solve_ivp, odeint\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from numba import jit, njit, prange\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "from collections import Counter\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:09:51.855100500Z",
     "start_time": "2023-12-22T03:09:51.829737600Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 33\n",
    "np.random.seed(SEED)\n",
    "\n",
    "os.makedirs('media', exist_ok=True)\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "if not os.path.isfile('predator-prey-data.csv'):\n",
    "    raise FileNotFoundError(\"File 'predator-prey-data.csv' not found.\")\n",
    "\n",
    "DATA = pd.read_csv('predator-prey-data.csv').drop(columns=['Unnamed: 0'])\n",
    "DATA_T, DATA_X, DATA_Y = DATA['t'].to_numpy(\n",
    "), DATA['x'].to_numpy(), DATA['y'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:09:52.352209900Z",
     "start_time": "2023-12-22T03:09:52.318234700Z"
    }
   },
   "outputs": [],
   "source": [
    "LOW_PARAM_BOUND = 0\n",
    "UP_PARAM_BOUND = 2\n",
    "MAX_STEPS_HILLCLIMING = 500\n",
    "MAX_ITER_SA = 500\n",
    "MSE_THRESH = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:09:54.060437300Z",
     "start_time": "2023-12-22T03:09:52.864651200Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), layout='tight')\n",
    "plt.scatter(DATA_T, DATA_X, s=10, label='Predator')\n",
    "plt.scatter(DATA_T, DATA_Y, s=10, label='Prey')\n",
    "plt.title('Predator-Prey dynamics of dataset')\n",
    "plt.xlabel('Time $t$')\n",
    "plt.ylabel('Population size $N$')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.savefig('media/dataset.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predator-Prey ODEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:09:54.118149Z",
     "start_time": "2023-12-22T03:09:54.058335800Z"
    }
   },
   "outputs": [],
   "source": [
    "def solve_lv(params, init_conditions, t):\n",
    "    alpha, beta, gamma, delta = params\n",
    "\n",
    "    def lv_odes(y, t):\n",
    "        x, z = y\n",
    "        dxdt = alpha*x - beta*x*z\n",
    "        dzdt = delta*x*z - gamma*z\n",
    "        return np.array([dxdt, dzdt])\n",
    "\n",
    "    solution = odeint(lv_odes, init_conditions, t)\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization algorithms and utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:09:55.678225700Z",
     "start_time": "2023-12-22T03:09:55.631425800Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_initial_random_guess(lower_bound=LOW_PARAM_BOUND, upper_bound=UP_PARAM_BOUND):\n",
    "    alpha = random.uniform(lower_bound, upper_bound)\n",
    "    beta = random.uniform(lower_bound, upper_bound)\n",
    "    gamma = random.uniform(lower_bound, upper_bound)\n",
    "    delta = random.uniform(lower_bound, upper_bound)\n",
    "    return [alpha, beta, gamma, delta]\n",
    "\n",
    "\n",
    "def get_neighbors(solution, step_size=0.1):\n",
    "    \"\"\"Calculate the neighbors of a solution, given a step size.\"\"\"\n",
    "    neighbors = []\n",
    "    for i in range(len(solution)):\n",
    "        # Add step_size to the parameter if it doesn't exceed PARAM_MAX\n",
    "        if solution[i] + step_size <= UP_PARAM_BOUND:\n",
    "            neighbors.append(\n",
    "                [solution[j] if j != i else solution[i] + step_size for j in range(len(solution))])\n",
    "        # Subtract step_size from the parameter if it doesn't become less than PARAM_MIN\n",
    "        if solution[i] - step_size >= LOW_PARAM_BOUND:\n",
    "            neighbors.append(\n",
    "                [solution[j] if j != i else solution[i] - step_size for j in range(len(solution))])\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "def choose_next_step(loss_function, current_step):\n",
    "    neighbors = get_neighbors(current_step)\n",
    "    return min(neighbors, key=loss_function)\n",
    "\n",
    "\n",
    "def hill_climbing(loss_function, initial_step, max_steps):\n",
    "    \"\"\"Perform the Hill Climbing optimization algorithm.\"\"\"\n",
    "    current_step = initial_step\n",
    "    history = [current_step]\n",
    "\n",
    "    for _ in range(max_steps):\n",
    "        try:\n",
    "            next_step = choose_next_step(loss_function, current_step)\n",
    "            if loss_function(next_step) >= loss_function(current_step):\n",
    "                break\n",
    "            history.append(next_step)\n",
    "            current_step = next_step\n",
    "        except Exception as e:\n",
    "            logging.error(\n",
    "                f\"An error occurred during the hill climbing: {str(e)}\")\n",
    "            break\n",
    "\n",
    "    return current_step, history\n",
    "\n",
    "\n",
    "def classic_annealing(*args, **kwargs):\n",
    "    return dual_annealing(*args, **kwargs, no_local_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:09:56.556567300Z",
     "start_time": "2023-12-22T03:09:56.509623200Z"
    }
   },
   "outputs": [],
   "source": [
    "def mse_objective(params):\n",
    "    initial_conditions = [DATA_Y[0], DATA_X[0]]\n",
    "    sim_data = solve_lv(params, initial_conditions, DATA_T)\n",
    "    mse = mean_squared_error(DATA[['y', 'x']].values, sim_data)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def mae_objective(params):\n",
    "    initial_conditions = [DATA_Y[0], DATA_X[0]]\n",
    "    sim_data = solve_lv(params, initial_conditions, DATA_T)\n",
    "    mae = mean_absolute_error(DATA[['y', 'x']].values, np.abs(sim_data))\n",
    "    return mae\n",
    "\n",
    "\n",
    "def mse_objective_mod(params, data):\n",
    "    valid_data = data.dropna(subset=['y', 'x'])\n",
    "    if valid_data.empty:\n",
    "        return float('inf')\n",
    "\n",
    "    initial_conditions = [valid_data['y'].iloc[0], valid_data['x'].iloc[0]]\n",
    "    sim_data = solve_lv(params, initial_conditions, valid_data['t'])\n",
    "    return mean_squared_error(valid_data[['y', 'x']].values, sim_data)\n",
    "\n",
    "\n",
    "def mae_objective_mod(params, data):\n",
    "    valid_data = data.dropna(subset=['y', 'x'])\n",
    "    if valid_data.empty:\n",
    "        return float('inf')\n",
    "\n",
    "    initial_conditions = [valid_data['y'].iloc[0], valid_data['x'].iloc[0]]\n",
    "    sim_data = solve_lv(params, initial_conditions, valid_data['t'])\n",
    "    return mean_absolute_error(valid_data[['y', 'x']].values, sim_data)\n",
    "\n",
    "\n",
    "def smape_objective_mod(params, data):\n",
    "    valid_data = data.dropna(subset=['y', 'x'])\n",
    "    if valid_data.empty:\n",
    "        return float('inf')\n",
    "\n",
    "    initial_conditions = [valid_data['y'].iloc[0], valid_data['x'].iloc[0]]\n",
    "    sim_data = solve_lv(params, initial_conditions, valid_data['t'])\n",
    "    absolute_percentage_error = 2 * np.abs((sim_data - valid_data[['y', 'x']].values) /\n",
    "                                           (np.abs(sim_data) + np.abs(valid_data[['y', 'x']].values)))\n",
    "    return np.nanmean(absolute_percentage_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:10:10.250024700Z",
     "start_time": "2023-12-22T03:09:57.009224100Z"
    }
   },
   "outputs": [],
   "source": [
    "bounds = [(LOW_PARAM_BOUND, UP_PARAM_BOUND)] * 4\n",
    "initial_guess = get_initial_random_guess()\n",
    "hc_optimizers = [hill_climbing]\n",
    "hc_names = ['Hill Climbing']\n",
    "sa_optimizers = [classic_annealing, dual_annealing]\n",
    "sa_names = ['Classic Annealing', 'Dual Annealing']\n",
    "optimizers = hc_optimizers + sa_optimizers\n",
    "objectives = [mse_objective, mae_objective]\n",
    "obj_names = ['MSE', 'MAE']\n",
    "est_params = {opt.__name__: {obj.__name__: []\n",
    "                             for obj in objectives} for opt in optimizers}\n",
    "\n",
    "for obj in objectives:\n",
    "    for opt in hc_optimizers:\n",
    "        params, _ = hill_climbing(\n",
    "            obj, initial_guess, max_steps=MAX_STEPS_HILLCLIMING)\n",
    "        est_params[opt.__name__][obj.__name__] = params\n",
    "        logging.info(\n",
    "            f\"Params of {opt.__name__} with {obj.__name__}: {[f'{p:.3f}' for p in params]} - Loss: {obj(params):.2e}\")\n",
    "    for opt in sa_optimizers:\n",
    "        params = opt(obj, bounds=bounds, maxiter=MAX_ITER_SA).x\n",
    "        est_params[opt.__name__][obj.__name__] = params\n",
    "        logging.info(\n",
    "            f\"Params of {opt.__name__} with {obj.__name__}: {[f'{p:.3f}' for p in params]} - Loss: {obj(params):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:10:12.061478600Z",
     "start_time": "2023-12-22T03:10:10.259002600Z"
    }
   },
   "outputs": [],
   "source": [
    "alphas = [0.6, 0.8]\n",
    "\n",
    "\n",
    "def plot_comparison_optimizers(hc_optimizers, sa_optimizers, objective=mse_objective, linestyles=['-', '--', ':'], colors=['tab:blue', 'tab:orange'], hc_names=hc_names, sa_names=sa_names, obj_names=obj_names):\n",
    "    t_detail = np.linspace(0, 20, 1000)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5), layout='tight', sharey=True)\n",
    "    fig.suptitle(\n",
    "        f'Comparison of simulations with the experimental dataset by optimization algorithms using MSE')\n",
    "    axs[0].scatter(DATA_T, DATA_X, s=10, color=colors[0])\n",
    "    axs[0].scatter(DATA_T, DATA_Y, s=10, color=colors[1])\n",
    "    for i, (opt, name) in enumerate(zip(hc_optimizers, hc_names)):\n",
    "        params = est_params[opt.__name__][objective.__name__]\n",
    "        initial_conditions = [DATA_Y[0], DATA_X[0]]\n",
    "        sim_data = solve_lv(params, initial_conditions, t_detail)\n",
    "        axs[0].plot(t_detail, sim_data[:, 1],\n",
    "                    label=f'Predator ({name})', linestyle=linestyles[i], color=colors[0], linewidth=2, alpha=0.8)\n",
    "        axs[0].plot(t_detail, sim_data[:, 0],\n",
    "                    label=f'Prey ({name})', linestyle=linestyles[i], color=colors[1], linewidth=2, alpha=0.8)\n",
    "    axs[0].set_title('Hill climbing-optimized model')\n",
    "    axs[0].set_xlabel('Time $t$')\n",
    "    axs[0].set_ylabel('Population size $N$')\n",
    "    axs[0].legend(loc='upper right')\n",
    "    axs[0].grid(True)\n",
    "    axs[1].scatter(DATA_T, DATA_X, s=10, color=colors[0])\n",
    "    axs[1].scatter(DATA_T, DATA_Y, s=10, color=colors[1])\n",
    "    for i, (opt, name, alpha) in enumerate(zip(sa_optimizers, sa_names, alphas)):\n",
    "        params = est_params[opt.__name__][objective.__name__]\n",
    "        initial_conditions = [DATA_Y[0], DATA_X[0]]\n",
    "        sim_data = solve_lv(params, initial_conditions, t_detail)\n",
    "        axs[1].plot(t_detail, sim_data[:, 1],\n",
    "                    label=f'Predator ({name})', linestyle=linestyles[i], color=colors[0], linewidth=1.5, alpha=alpha)\n",
    "        axs[1].plot(t_detail, sim_data[:, 0],\n",
    "                    label=f'Prey ({name})', linestyle=linestyles[i], color=colors[1], linewidth=1.5, alpha=alpha)\n",
    "    axs[1].set_title('Simulated annealing-optimized model')\n",
    "    axs[1].set_xlabel('Time $t$')\n",
    "    axs[1].legend(loc='upper right')\n",
    "    axs[1].grid(True)\n",
    "    plt.savefig('media/comparison_optimizers.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_comparison_optimizers(hc_optimizers, sa_optimizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing samples functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:16:10.601754700Z",
     "start_time": "2023-12-22T03:10:12.069326100Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_sample_dataset(data, frac):\n",
    "    data = data.copy()\n",
    "    return data.sample(frac=frac).sort_values(by='t').reset_index(drop=True)\n",
    "\n",
    "\n",
    "def batch_comparison_by_frac(fracs, n_samples=10, optimizer=classic_annealing, objective=mse_objective, initial_conditions=[DATA_Y[0], DATA_X[0]], data=DATA, **kwargs):\n",
    "    results = []\n",
    "    with tqdm(total=len(fracs)*n_samples) as pbar:\n",
    "        for frac in fracs:\n",
    "            mse = []\n",
    "            for _ in range(n_samples):\n",
    "                sample_data = gen_sample_dataset(data, frac)\n",
    "                params = optimizer(objective, **kwargs).x\n",
    "                sim_data = solve_lv(\n",
    "                    params, initial_conditions, sample_data['t'])\n",
    "                mse.append(mean_squared_error(\n",
    "                    sample_data[['y', 'x']].values, sim_data))\n",
    "                pbar.update()\n",
    "            mean_mse, std_mse = np.mean(mse), np.std(mse)\n",
    "            conf_int = sp.stats.norm.interval(\n",
    "                0.95, loc=mean_mse, scale=std_mse)\n",
    "            results.append([frac, mean_mse, std_mse, conf_int])\n",
    "        logging.info(f\"params: {params}\")\n",
    "        logging.info(\n",
    "            f\"Minimum and Maximum of sim_data: {sim_data.min()}, {sim_data.max()}\")\n",
    "        logging.info(\n",
    "            f\"MSE: {mean_squared_error(sample_data[['y', 'x']].values, sim_data)}\")\n",
    "\n",
    "    return pd.DataFrame(results, columns=['frac', 'mean', 'std', 'conf_int'])\n",
    "\n",
    "\n",
    "def batch_comparison_by_frac_and_variable(data, fracs, data_variable, n_samples=10,\n",
    "                                          optimizer=classic_annealing,\n",
    "                                          objective=mse_objective_mod,\n",
    "                                          **kwargs):\n",
    "    results = []\n",
    "    with tqdm(total=len(fracs) * n_samples) as pbar:\n",
    "        for frac in fracs:\n",
    "            mse = []\n",
    "            for _ in range(n_samples):\n",
    "                sample_data = gen_sample_dataset(data, frac)\n",
    "                params = optimizer(lambda params: objective(\n",
    "                    params, sample_data), **kwargs).x\n",
    "                initial_conditions = [\n",
    "                    sample_data['y'].iloc[0], sample_data['x'].iloc[0]]\n",
    "                sim_data = solve_lv(\n",
    "                    params, initial_conditions, sample_data['t'])\n",
    "                mse.append(mean_squared_error(\n",
    "                    sample_data[data_variable].values, sim_data[:, {'y': 0, 'x': 1}[data_variable]]))\n",
    "                pbar.update()\n",
    "            mean_mse, std_mse = np.mean(mse), np.std(mse)\n",
    "            conf_int = sp.stats.norm.interval(\n",
    "                0.95, loc=mean_mse, scale=std_mse)\n",
    "            results.append([frac, mean_mse, std_mse, conf_int])\n",
    "        logging.info(f\"params: {params}\")\n",
    "        logging.info(\n",
    "            f\"Minimum and Maximum of sim_data: {sim_data.min()}, {sim_data.max()}\")\n",
    "        logging.info(\n",
    "            f\"MSE: {mean_squared_error(sample_data[data_variable].values, sim_data[:, {'y': 0, 'x': 1}[data_variable]])}\")\n",
    "    return pd.DataFrame(results, columns=['frac', 'mean', 'std', 'conf_int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:16:10.688378400Z",
     "start_time": "2023-12-22T03:16:10.619036200Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    fracs = np.linspace(0.1, 1.0, 10)\n",
    "    experiment_df = batch_comparison_by_frac(\n",
    "        fracs=fracs, n_samples=20, bounds=bounds, maxiter=MAX_ITER_SA)\n",
    "    print(experiment_df.head())\n",
    "    plt.figure(figsize=(6, 4), layout='tight')\n",
    "    plt.plot(experiment_df['frac'], experiment_df['mean'], label='Mean')\n",
    "    plt.fill_between(experiment_df['frac'], experiment_df['conf_int'].apply(\n",
    "        lambda x: x[0]), experiment_df['conf_int'].apply(lambda x: x[1]), alpha=0.2, label='95% confidence interval')\n",
    "    plt.plot(experiment_df['frac'], [MSE_THRESH]*len(experiment_df['frac']),\n",
    "             label='MSE threshold', linestyle='--', color='tab:red')\n",
    "    plt.title('Mean and confidence interval of MSE by fraction of dataset')\n",
    "    plt.xlabel('Fraction of dataset')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('media/frac_conf_mse_sa.png', dpi=300)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:31:33.525315900Z",
     "start_time": "2023-12-22T03:16:10.645849600Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), layout='tight')\n",
    "for data_variable in ['y', 'x']:\n",
    "    try:\n",
    "        experiment_df = batch_comparison_by_frac_and_variable(fracs=fracs, data_variable=data_variable,\n",
    "                                                              n_samples=20, bounds=bounds, maxiter=MAX_ITER_SA,\n",
    "                                                              data=DATA, objective=mse_objective_mod)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "    plt.plot(experiment_df['frac'], experiment_df['mean'],\n",
    "             label=f'{data_variable} (Mean $\\\\mu$)')\n",
    "    plt.fill_between(experiment_df['frac'],\n",
    "                     experiment_df['conf_int'].apply(lambda x: x[0]),\n",
    "                     experiment_df['conf_int'].apply(lambda x: x[1]),\n",
    "                     alpha=0.2, label=f'{data_variable} (95% CI)')\n",
    "plt.title(f'Mean and confidence interval of MSE by fraction of dataset')\n",
    "plt.xlabel('Fraction of dataset')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.savefig('media/frac_conf_mse_sa_by_var.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:47:00.250334900Z",
     "start_time": "2023-12-22T03:31:33.524315400Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), layout='tight')\n",
    "for data_variable in ['y', 'x']:\n",
    "    try:\n",
    "        experiment_df = batch_comparison_by_frac_and_variable(fracs=fracs, data_variable='x',\n",
    "                                                              n_samples=20, bounds=bounds, maxiter=MAX_ITER_SA,\n",
    "                                                              data=DATA, objective=smape_objective_mod)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "\n",
    "    plt.plot(experiment_df['frac'], experiment_df['mean'],\n",
    "             label=f'{data_variable} (Mean $\\\\mu$)')\n",
    "    plt.fill_between(experiment_df['frac'],\n",
    "                     experiment_df['conf_int'].apply(lambda x: x[0]),\n",
    "                     experiment_df['conf_int'].apply(lambda x: x[1]),\n",
    "                     alpha=0.2, label=f'{data_variable} (95% CI)')\n",
    "plt.title(f'Mean and confidence interval of sMAPE by fraction of dataset')\n",
    "plt.xlabel('Fraction of dataset')\n",
    "plt.ylabel('sMAPE')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.savefig('media/frac_conf_smape_sa_by_var.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many data-points from each time-series you could remove until you are not able to reverse-engineer the parameters any more?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, try to find the importance of each time-series on reverse-engineering process by ﬁxing one time-series and removing data-points from the other one. In this way, you will ﬁnd the critical number of data-points for each time-series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T04:00:50.955064600Z",
     "start_time": "2023-12-22T04:00:50.844456900Z"
    }
   },
   "outputs": [],
   "source": [
    "def prune_data_series(data, variable, frac_to_remove):\n",
    "    logging.info(\n",
    "        f\"\\nAttempting to prune {frac_to_remove*100}% of '{variable}' data...\")\n",
    "    if not isinstance(frac_to_remove, (float, int)):\n",
    "        raise TypeError('frac_to_remove should be a float or an integer.')\n",
    "    if not 0 <= frac_to_remove <= 1:\n",
    "        raise ValueError('frac_to_remove should be between 0 and 1 inclusive.')\n",
    "\n",
    "    num_data_to_prune = int(len(data) * frac_to_remove)\n",
    "    logging.info(f\"Number of data points to prune: {num_data_to_prune}\")\n",
    "\n",
    "    pruned_data = data.copy()\n",
    "    if num_data_to_prune > 0:\n",
    "        prune_indices = np.random.choice(\n",
    "            data.index, size=num_data_to_prune, replace=False)\n",
    "        pruned_data.loc[prune_indices, variable] = np.nan\n",
    "        logging.info(\n",
    "            f\"Pruned data. Remaining data points: {pruned_data.dropna(subset=[variable]).shape[0]}\")\n",
    "    else:\n",
    "        logging.warning(\n",
    "            \"No data points to prune based on the fraction provided.\")\n",
    "\n",
    "    return pruned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T04:00:55.040605200Z",
     "start_time": "2023-12-22T04:00:54.960244700Z"
    }
   },
   "outputs": [],
   "source": [
    "def optimize_with_pruned_data(pruned_data, optimizer, objective_function, bounds):\n",
    "    logging.info(\"\\nOptimizing with pruned data...\")\n",
    "    valid_data = pruned_data.dropna(subset=['y', 'x'])\n",
    "    if valid_data.shape[0] < 2:\n",
    "        logging.warning(\n",
    "            \"Not enough data points after pruning to perform optimization.\")\n",
    "        return None, float('inf')\n",
    "\n",
    "    initial_conditions = [valid_data['y'].iloc[0], valid_data['x'].iloc[0]]\n",
    "    try:\n",
    "        result = optimizer(lambda params: objective_function(\n",
    "            params, valid_data), bounds=bounds, maxiter=MAX_ITER_SA)\n",
    "        logging.info(\"Optimization successful.\")\n",
    "        return result.x, result.fun\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred during optimization: {e}\")\n",
    "        return None, float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T04:01:48.052532500Z",
     "start_time": "2023-12-22T04:00:57.699299500Z"
    }
   },
   "outputs": [],
   "source": [
    "# fractions = [round(float(i)/10, 1) for i in range(11)]\n",
    "fractions = np.linspace(0.1, 1.0, 5)\n",
    "objectives_mod = [mse_objective_mod, mae_objective_mod, smape_objective_mod]\n",
    "# objectives_mod = [mse_objective_mod]\n",
    "names = ['MSE', 'MAE', 'sMAPE']\n",
    "n_sim = 15\n",
    "\n",
    "plt.figure(figsize=(8, 5), layout='tight')\n",
    "with tqdm(total=2*len(fractions)*len(objectives_mod)*n_sim) as pbar:\n",
    "    for objective, name in zip(objectives_mod, names):\n",
    "        results = []\n",
    "        for variable in ['x', 'y']:\n",
    "            for frac in fractions:\n",
    "                losses = []\n",
    "                for n in range(n_sim):\n",
    "                    pruned_data = prune_data_series(DATA, variable, frac)\n",
    "                    params, loss = optimize_with_pruned_data(\n",
    "                        pruned_data, classic_annealing, objective_function=objective, bounds=bounds)\n",
    "                    losses.append(loss)\n",
    "                    pbar.update()\n",
    "                results.append({\n",
    "                    'variable': variable,\n",
    "                    'fraction_removed': frac,\n",
    "                    'loss': np.mean(losses)\n",
    "                })\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        for variable in ['x', 'y']:\n",
    "            variable_results = results_df[results_df['variable'] == variable]\n",
    "            plt.plot(variable_results['fraction_removed'],\n",
    "                     variable_results['loss'], label=f'{name} - {variable} data pruned')\n",
    "\n",
    "    plt.xlabel('Fraction of data removed')\n",
    "    plt.ylabel(f'Error after optimization')\n",
    "    plt.legend()\n",
    "    plt.title('Impact of Data Pruning on Parameter Estimation')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'media/pruning_1.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, if you combine two reduced time-series, could you still infer the parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-22T02:34:11.110130Z"
    }
   },
   "outputs": [],
   "source": [
    "fractions = np.arange(0.1, 1.0, 0.1)\n",
    "n_sim = 15\n",
    "\n",
    "with tqdm(total=2*len(fractions)*n_sim) as pbar:\n",
    "    results = []\n",
    "    for variable in ['x', 'y']:\n",
    "        for frac in fractions:\n",
    "            losses = []\n",
    "            for n in range(n_sim):\n",
    "                pruned_data = prune_data_series(DATA, variable, frac)\n",
    "                params, loss = optimize_with_pruned_data(\n",
    "                    pruned_data, classic_annealing, objective_function=mse_objective_mod, bounds=bounds)\n",
    "                losses.append(loss)\n",
    "                pbar.update()\n",
    "            results.append({\n",
    "                'variable': variable,\n",
    "                'fraction_removed': frac,\n",
    "                'loss': np.mean(losses)\n",
    "            })\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    for variable in ['x', 'y']:\n",
    "        variable_results = results_df[results_df['variable'] == variable]\n",
    "        plt.plot(variable_results['fraction_removed'],\n",
    "                 variable_results['loss'], label=f'{variable} data pruned')\n",
    "\n",
    "    plt.xlabel('Fraction of data removed')\n",
    "    plt.ylabel(f'MSE after optimization')\n",
    "    plt.legend()\n",
    "    plt.title('Impact of Data Pruning on Parameter Estimation')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-22T02:34:11.112130800Z"
    }
   },
   "outputs": [],
   "source": [
    "def prune_both_series(data, frac_to_remove):\n",
    "    pruned_data = data.copy()\n",
    "    prune_indices = np.random.choice(data.index, size=int(\n",
    "        len(data) * frac_to_remove), replace=False)\n",
    "    pruned_data.loc[prune_indices, ['x', 'y']] = np.nan\n",
    "    return pruned_data\n",
    "\n",
    "\n",
    "def run_optimization_on_pruned_data(fracs, n_samples=10, objectives=[mse_objective_mod, mae_objective_mod, smape_objective_mod]):\n",
    "    results = []\n",
    "    for frac in fracs:\n",
    "        for objective in objectives:\n",
    "            for _ in range(n_samples):\n",
    "                pruned_data = prune_both_series(DATA, frac)\n",
    "                initial_guess = get_initial_random_guess()\n",
    "\n",
    "                if objective in [mse_objective_mod, mae_objective_mod, smape_objective_mod]:\n",
    "                    # For modified objectives, pass both parameters and data\n",
    "                    params, _ = hill_climbing(lambda params: objective(\n",
    "                        params, pruned_data), initial_guess, max_steps=MAX_STEPS_HILLCLIMING)\n",
    "                else:\n",
    "                    # For standard objectives, pass only parameters\n",
    "                    params, _ = hill_climbing(\n",
    "                        objective, initial_guess, max_steps=MAX_STEPS_HILLCLIMING)\n",
    "\n",
    "                loss = objective(params, pruned_data)\n",
    "                results.append(\n",
    "                    {'frac': frac, 'objective': objective.__name__, 'loss': loss})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "fractions = np.arange(0.1, 1.0, 0.1)\n",
    "experiment_results = run_optimization_on_pruned_data(fractions, n_samples=15)\n",
    "\n",
    "for objective_name in ['mse_objective_mod', 'mae_objective_mod', 'smape_objective_mod']:\n",
    "    subset = experiment_results[experiment_results['objective']\n",
    "                                == objective_name]\n",
    "    plt.plot(subset['frac'], subset['loss'], label=objective_name)\n",
    "\n",
    "plt.xlabel('Fraction of data removed')\n",
    "plt.ylabel('Loss after optimization')\n",
    "plt.legend()\n",
    "plt.title('Parameter Estimation with Combined Data Reduction')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does removing every data-point have the same effect on reverse-engineering process? In other words, what are the points that you could remove safely without affecting the inferance procedure? and what are those with critical effects on the process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_analysis(data, initial_guess, bounds, maxiter):\n",
    "    importance_scores = []\n",
    "\n",
    "    for i in tqdm(range(len(data)), desc=\"Analyzing Data Points\"):\n",
    "        # Exclude one data point\n",
    "        reduced_data = data.drop(index=i)\n",
    "        t_reduced, x_reduced, y_reduced = reduced_data['t'].to_numpy(\n",
    "        ), reduced_data['x'].to_numpy(), reduced_data['y'].to_numpy()\n",
    "\n",
    "        def mse_objective_reduced(params):\n",
    "            initial_conditions = [y_reduced[0], x_reduced[0]]\n",
    "            simulated = solve_lv(params, initial_conditions, t_reduced)\n",
    "            mse = np.mean((simulated - reduced_data[['y', 'x']].values) ** 2)\n",
    "            return mse\n",
    "\n",
    "        # Fit the model on the reduced dataset\n",
    "        result = classic_annealing(\n",
    "            mse_objective_reduced, bounds=bounds, maxiter=maxiter)\n",
    "        params = result.x\n",
    "        mse = mse_objective_reduced(params)\n",
    "        importance_scores.append((i, mse))\n",
    "\n",
    "    return importance_scores\n",
    "\n",
    "\n",
    "mse_list = []\n",
    "n_sims = 10\n",
    "for sims in range(n_sims):\n",
    "    importance_scores = leave_one_out_analysis(\n",
    "        DATA, initial_guess, bounds, MAX_ITER_SA)\n",
    "    importance_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    mse_list.append(importance_scores[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list of MSEs\n",
    "flat_mse_list = [item for sublist in mse_list for item in sublist]\n",
    "\n",
    "# Count the frequency of each data point\n",
    "data_point_frequencies = Counter(\n",
    "    [datapoint for datapoint, mse in flat_mse_list])\n",
    "total_entries = len(flat_mse_list)\n",
    "probability_distribution = {\n",
    "    datapoint: freq / total_entries for datapoint, freq in data_point_frequencies.items()}\n",
    "\n",
    "# Create Dataframe\n",
    "probability_df = pd.DataFrame(list(probability_distribution.items()), columns=[\n",
    "                              'Data Point', 'Probability'])\n",
    "\n",
    "probability_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'font.size': 13})\n",
    "\n",
    "# Sort the DataFrame for better visualization\n",
    "probability_df_sorted = probability_df.sort_values(\n",
    "    by='Probability', ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 6))  # You can adjust the figure size as needed\n",
    "plt.bar(probability_df_sorted['Data Point'],\n",
    "        probability_df_sorted['Probability'], color='blue')\n",
    "\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Probability Distribution of Data Points Being In the Top 10 Highest Influence from 10 Simulations')\n",
    "plt.savefig('media/probability_distribution_datap.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All points that occur in the probability DF will be highlighted\n",
    "n_highlight = len(probability_df)\n",
    "\n",
    "# Sort the DataFrame\n",
    "high_probability_indices = probability_df.sort_values(\n",
    "    by='Probability', ascending=False).head(n_highlight)['Data Point']\n",
    "\n",
    "# Plot the original data\n",
    "plt.scatter(DATA['t'], DATA['x'], label='Predator', alpha=0.7)\n",
    "plt.scatter(DATA['t'], DATA['y'], label='Prey', alpha=0.7)\n",
    "\n",
    "# Highlight the points\n",
    "for idx in high_probability_indices:\n",
    "    plt.scatter(DATA.loc[idx, 't'], DATA.loc[idx, 'x'],\n",
    "                color='blue', edgecolor='black', s=50)\n",
    "    plt.scatter(DATA.loc[idx, 't'], DATA.loc[idx, 'y'],\n",
    "                color='red', edgecolor='black', s=50)\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Population')\n",
    "plt.title('Predator-Prey Data with High Impact Points Highlighted')\n",
    "plt.legend(loc=\"upper right\", fontsize='small')\n",
    "plt.savefig('media/high_probability_points_plot.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_highlight = 10\n",
    "\n",
    "# Plot the original data\n",
    "plt.scatter(DATA['t'], DATA['x'], label='Predator', alpha=0.7)\n",
    "plt.scatter(DATA['t'], DATA['y'], label='Prey', alpha=0.7)\n",
    "\n",
    "# Highlight the points with highest probability\n",
    "for idx in high_probability_indices:\n",
    "    plt.scatter(DATA.loc[idx, 't'], DATA.loc[idx, 'x'],\n",
    "                color='blue', edgecolor='black', s=50)\n",
    "    plt.scatter(DATA.loc[idx, 't'], DATA.loc[idx, 'y'],\n",
    "                color='red', edgecolor='black', s=50)\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Population')\n",
    "plt.title('Predator-Prey Data with the Highest Probability Points Highlighted')\n",
    "plt.legend(loc=\"upper right\", fontsize='small')\n",
    "plt.savefig('media/high_probability_points_plot.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\<Extra question\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-22T02:34:11.119129800Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
