{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T12:10:13.798230400Z",
     "start_time": "2023-12-13T12:10:12.336929800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.optimize import dual_annealing, curve_fit\n",
    "from scipy.integrate import solve_ivp, odeint\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from numba import jit, njit, prange\n",
    "import math\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T12:10:13.857051400Z",
     "start_time": "2023-12-13T12:10:13.799737700Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 33\n",
    "np.random.seed(SEED)\n",
    "\n",
    "os.makedirs('media', exist_ok=True)\n",
    "\n",
    "if not os.path.isfile('predator-prey-data.csv'):\n",
    "    raise FileNotFoundError(\"File 'predator-prey-data.csv' not found.\")\n",
    "\n",
    "data = pd.read_csv('predator-prey-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T12:10:13.859119500Z",
     "start_time": "2023-12-13T12:10:13.829874100Z"
    }
   },
   "outputs": [],
   "source": [
    "LOW_PARAM_BOUND = 0\n",
    "UP_PARAM_BOUND = 2\n",
    "MAX_STEPS_HILLCLIMING = 500\n",
    "MAX_ITER_SA = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T12:10:14.141792Z",
     "start_time": "2023-12-13T12:10:13.849357300Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), layout='tight')\n",
    "plt.scatter(data['t'], data['x'], s=10, label='Predator')\n",
    "plt.scatter(data['t'], data['y'], s=10, label='Prey')\n",
    "plt.title('Predator-Prey dynamics of dataset')\n",
    "plt.xlabel('Time $t$')\n",
    "plt.ylabel('Population size $N$')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('media/dataset.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T12:10:14.162243400Z",
     "start_time": "2023-12-13T12:10:14.140753Z"
    }
   },
   "outputs": [],
   "source": [
    "def solve_lv(params, init_conditions, t):\n",
    "    alpha, beta, gamma, delta = params\n",
    "\n",
    "    def lv_odes(y, t):\n",
    "        x, z = y\n",
    "        dxdt = alpha*x - beta*x*z\n",
    "        dzdt = delta*x*z - gamma*z\n",
    "        return np.array([dxdt, dzdt])\n",
    "\n",
    "    solution = odeint(lv_odes, init_conditions, t)\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_random_guess(lower_bound=LOW_PARAM_BOUND, upper_bound=UP_PARAM_BOUND):\n",
    "    alpha = random.uniform(lower_bound, upper_bound)\n",
    "    beta = random.uniform(lower_bound, upper_bound)\n",
    "    gamma = random.uniform(lower_bound, upper_bound)\n",
    "    delta = random.uniform(lower_bound, upper_bound)\n",
    "    return [alpha, beta, gamma, delta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T12:10:14.269496100Z",
     "start_time": "2023-12-13T12:10:14.163277600Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_neighbors(solution, step_size=0.1):\n",
    "    \"\"\"Calculate the neighbors of a solution, given a step size.\"\"\"\n",
    "    neighbors = []\n",
    "    for i in range(len(solution)):\n",
    "        # Add step_size to the parameter if it doesn't exceed PARAM_MAX\n",
    "        if solution[i] + step_size <= UP_PARAM_BOUND:\n",
    "            neighbors.append(\n",
    "                [solution[j] if j != i else solution[i] + step_size for j in range(len(solution))])\n",
    "        # Subtract step_size from the parameter if it doesn't become less than PARAM_MIN\n",
    "        if solution[i] - step_size >= LOW_PARAM_BOUND:\n",
    "            neighbors.append(\n",
    "                [solution[j] if j != i else solution[i] - step_size for j in range(len(solution))])\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "def choose_next_step(loss_function, current_step):\n",
    "    neighbors = get_neighbors(current_step)\n",
    "    return min(neighbors, key=loss_function)\n",
    "\n",
    "\n",
    "def hill_climbing(loss_function, initial_step, max_steps):\n",
    "    \"\"\"Perform the Hill Climbing optimization algorithm.\"\"\"\n",
    "    current_step = initial_step\n",
    "    history = [current_step]\n",
    "\n",
    "    for _ in range(max_steps):\n",
    "        try:\n",
    "            next_step = choose_next_step(loss_function, current_step)\n",
    "            if loss_function(next_step) >= loss_function(current_step):\n",
    "                break\n",
    "            history.append(next_step)\n",
    "            current_step = next_step\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during the hill climbing: {str(e)}\")\n",
    "            break\n",
    "\n",
    "    return current_step, history\n",
    "\n",
    "def classic_annealing(*args, **kwargs):\n",
    "    return dual_annealing(*args, **kwargs, no_local_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T12:10:14.271499100Z",
     "start_time": "2023-12-13T12:10:14.177709700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mse_objective(params):\n",
    "    initial_conditions = [data['y'][0], data['x'][0]]\n",
    "    simulated = solve_lv(params, initial_conditions, data['t'])\n",
    "    mse = np.mean((simulated - data[['y', 'x']].values) ** 2)\n",
    "    return mse\n",
    "\n",
    "def mae_objective(params):\n",
    "    initial_conditions = [data['y'][0], data['x'][0]]\n",
    "    simulated = solve_lv(params, initial_conditions, data['t'])\n",
    "    mae = np.mean(np.abs(simulated - data[['y', 'x']].values))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T12:10:19.933949Z",
     "start_time": "2023-12-13T12:10:14.222823200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bounds = [(LOW_PARAM_BOUND, UP_PARAM_BOUND)] * 4\n",
    "initial_guess = get_initial_random_guess()\n",
    "hc_optimizers = [hill_climbing]\n",
    "sa_optimizers = [classic_annealing, dual_annealing]\n",
    "optimizers = hc_optimizers + sa_optimizers\n",
    "objectives = [mse_objective, mae_objective]\n",
    "est_params = {opt.__name__: {obj.__name__: [] for obj in objectives} for opt in optimizers}\n",
    "\n",
    "\n",
    "for obj in objectives:\n",
    "    for opt in hc_optimizers:\n",
    "        params, _ = hill_climbing(\n",
    "            obj, initial_guess, max_steps=MAX_STEPS_HILLCLIMING)\n",
    "        est_params[opt.__name__][obj.__name__] = params\n",
    "        print(f\"Params of {opt.__name__} with {obj.__name__}: {[f'{p:.3f}' for p in params]} - Loss: {obj(params)}\")\n",
    "    for opt in sa_optimizers:\n",
    "        params = opt(obj, bounds=bounds, maxiter=MAX_ITER_SA).x\n",
    "        est_params[opt.__name__][obj.__name__] = params\n",
    "        print(f\"Params of {opt.__name__} with {obj.__name__}: {[f'{p:.3f}' for p in params]} - Loss: {obj(params)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing samples functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T12:10:21.066215500Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T12:10:21.077496300Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T12:10:21.078790900Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T12:10:21.080209500Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T12:10:21.081434500Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many data-points from each time-series you could remove until you are not able to reverse-engineer the parameters any more?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, try to ﬁnd the importance of each time-series on reverse-engineering process by ﬁxing one time-series and removing data-points from the other one. In this way, you will ﬁnd the critical number of data-points for each time-series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T12:10:21.082486300Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, if you combine two reduced time-series, could you still infer the parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T12:10:21.084480400Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does removing every data-point have the same effect on reverse-engineering process? In other words, what are the points that you could remove safely without affecting the inferance procedure? and what are those with critical effects on the process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T12:10:21.086508800Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\<Extra question\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T12:10:21.087617200Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
